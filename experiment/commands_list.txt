# A single job
sbatch --get-user-env --export=NONE --clusters=serial --partition=serial_std \
  --cpus-per-task=1 --mem=1000M --time=0:05:00 --job-name=test_single \
  --wrap="module load slurm_setup; source \$HOME/miniconda3/etc/profile.d/conda.sh; conda activate steinstadion-env; python \$HOME/steinstadion/test_script.py"

# An array of 5 tasks (IDs 0–4)
sbatch --get-user-env --export=NONE --clusters=serial --partition=serial_std \
  --cpus-per-task=1 --mem=1000M --time=0:05:00 --job-name=test_array5 --array=0-4 \
  --wrap="module load slurm_setup; source \$HOME/miniconda3/etc/profile.d/conda.sh; conda activate steinstadion-env; python \$HOME/steinstadion/test_script.py"

# Another single job
sbatch --get-user-env --export=NONE --clusters=serial --partition=serial_std \
  --cpus-per-task=1 --mem=1000M --time=0:05:00 --job-name=test_single2 \
  --wrap="module load slurm_setup; source \$HOME/miniconda3/etc/profile.d/conda.sh; conda activate steinstadion-env; python \$HOME/steinstadion/test_script.py"

# A bigger array (10 tasks, IDs 0–9)
sbatch --get-user-env --export=NONE --clusters=serial --partition=serial_std \
  --cpus-per-task=1 --mem=1000M --time=0:05:00 --job-name=test_array10 --array=0-9 \
  --wrap="module load slurm_setup; source \$HOME/miniconda3/etc/profile.d/conda.sh; conda activate steinstadion-env; python \$HOME/steinstadion/test_script.py"
